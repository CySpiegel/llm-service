networks:
  llm-service:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  qdrant_data:
  vllm_cache:
  grafana_data:
  n8n_data:
  flowise_data:
  neo4j_data:
  searxng_data:
  clickhouse_data:
  clickhouse_logs:

# This is a Docker Compose file for deploying a set of services related to LLM (Large Language Model) applications.
# It includes services for web UI, databases, vector databases, monitoring, and more.
# The services are designed to work together in a network called 'llm-service'.
# The file uses environment variables for configuration, which should be defined in a .env file or in the environment where this Docker Compose file is run.
# Make sure to set the necessary environment variables before running this file.
# The services include:
# - nginx: A reverse proxy server to route traffic to the appropriate services.
# - open-webui: A web UI for interacting with LLMs.
# - postgres: A PostgreSQL database for storing application data.
# - redis: A Redis instance for caching and message brokering.
# - qdrant: A vector database for similarity search.
# - vllm: A high-performance inference engine for LLMs.
# - litellm: A lightweight LLM management service.
# - prometheus: A monitoring and alerting toolkit.
# - grafana: A visualization tool for monitoring data.
# - redis_exporter: An exporter for Redis metrics.
# - postgres_exporter: An exporter for PostgreSQL metrics.
# - nvidia-dcgm-exporter: An exporter for NVIDIA GPU metrics.
# - cadvisor: A container monitoring tool.
# - dcgm-exporter: An NVIDIA Data Center GPU Manager exporter.
# - ollama: A service for running LLMs (optional, requires NVIDIA runtime).
# - flowise: A service for building and deploying LLM applications.
# - neo4j: A graph database for storing and querying graph data.
# - searxng: A privacy-respecting metasearch engine.
# - n8n: A workflow automation tool.
services:
  nginx:
    image: nginx:alpine
    container_name: nginx
    restart: unless-stopped
    ports:
      - "443:443" # open-webui
      - "8081:8081" # n8n
      - "8082:8082" # searxng
      - "8083:8083" # langfuse
      - "8084:8084" # minio
      - "8085:8085" # grafana
      - "8086:8086" # neo4j :8086/browser
      - "8087:8087" # qdrant
      - "8088:8088" # LiteLLM
      - "8089:8089" # Flowise
      - "8090:8090" # Prometheus
      - "8091:8091" # ClickHouse HTTP interface
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/certs:/etc/nginx/ssl:ro
    depends_on:
      - open-webui
      - n8n
      - grafana
      - flowise
      - langfuse
      - prometheus
      - searxng
    networks:
      - llm-service

  open-webui:
    image: ghcr.io/open-webui/open-webui:cuda
    container_name: open-webui
    restart: always
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/openwebui
      - REDIS_URL=redis://redis:6379
      - QDRANT_URI=http://qdrant:6333
      - VECTOR_DB=qdrant
      - QDRANT_ON_DISK=true
      - QDRANT_PREFER_GRPC=true
      - QDRANT_GRPC_PORT=6334
      - QDRANT_COLLECTION_PREFIX=open-webui
      - ENABLE_QDRANT_MULTITENANCY_MODE=true
      - ENABLE_AUTOCOMPLETE=false
      - ENABLE_TAGS_GENERATION=true
      - ENABLE_RETRIEVAL_QUERY_GENERATION=true
      - REDIS_TTL_SECONDS=3600
    # ports:
    #   - "3000:8080"
    expose:
      - 8080
    depends_on:
      - postgres
      - redis
      - qdrant
    deploy:
      resources:
        limits:
          cpus: '8.0'
          memory: 16G
        reservations:
          devices:
            - capabilities: [gpu]
    networks:
      - llm-service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  postgres:
    image: postgres:16-alpine
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres-init-multiple-db.sh:/docker-entrypoint-initdb.d/postgres-init-multiple-db.sh:ro
    expose:
      - "5432"
    networks:
      - llm-service
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER}"]
      interval: 30s
      timeout: 10s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: redis
    restart: always
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    expose:
      - "6379"
    networks:
      - llm-service
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
  
  # Qdrant is a high-performance vector database designed for similarity search and nearest neighbor search on high-dimensional data.
  # - Official docs: https://qdrant.tech/documentation/
  # - REST API: Port 6333
  # - gRPC API: Port 6334
  #
  # Features:
  #   - Supports multiple vector indexing methods (HNSW, FAISS, Annoy)
  #   - Offers both on-disk and in-memory storage options
  #   - Client libraries available for Python, JavaScript, Go, Rust, and more
  #
  # Note:
  #   - For GPU acceleration, ensure NVIDIA Container Toolkit is installed and the NVIDIA runtime is enabled.
  #   - Configure the storage backend and index type based on your performance requirements.
  qdrant:
    image: qdrant/qdrant
    container_name: qdrant
    restart: always
    volumes:
      - qdrant_data:/qdrant/storage
    expose:
     - "6333" # REST API
     - "6334" # gRPC
    networks:
      - llm-service
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:6333"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Make sure to have the NVIDIA Container Toolkit installed
  # If you want to use vLLM, ensure that the NVIDIA runtime is available and configured
  # properly on your Docker host.
  # vLLM is a high-performance inference engine for large language models.
  # It supports models from Hugging Face and other sources.
  # For more information, visit https://vllm.ai/
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    restart: unless-stopped
    runtime: nvidia
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
    command: >
      --model meta-llama/Meta-Llama-3-8B-Instruct
      --host 0.0.0.0
      --port 8000
      --dtype float16
    expose:
      - "8000"
    volumes:
      - ./vllm_cache:/root/.cache/huggingface/hub
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    networks:
      - llm-service

  litellm:
    image: ghcr.io/berriai/litellm:main-stable
    container_name: litellm
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/litellm
      - UI_USERNAME=${LITELLM_UI_USERNAME}
      - UI_PASSWORD=${LITELLM_UI_PASSWORD}
    expose:
      - "4000"
    networks:
      - llm-service
    command: ["--port", "4000"]
    restart: unless-stopped

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    restart: unless-stopped
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    expose:
      - "9090"
    networks:
      - llm-service
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:9090"]
      interval: 30s
      timeout: 10s
      retries: 5

  grafana:
    image: grafana/grafana
    container_name: grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    expose:
      - "3000"
    volumes:
      - ./grafana_data:/var/lib/grafana
    networks:
      - llm-service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 5

  redis_exporter:
    image: oliver006/redis_exporter
    container_name: redis_exporter
    restart: unless-stopped
    environment:
      - REDIS_ADDR=redis://redis:6379
    expose:
      - "9121"
    networks:
      - llm-service

  postgres_exporter:
    image: prometheuscommunity/postgres-exporter
    container_name: postgres_exporter
    restart: unless-stopped
    environment:
      - DATA_SOURCE_NAME=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable
    expose:
      - "9187"
    networks:
      - llm-service

  nvidia-dcgm-exporter:
    image: nvidia/dcgm-exporter:latest
    container_name: nvidia-dcgm-exporter
    restart: unless-stopped
    runtime: nvidia
    expose:
      - "9400"
    networks:
      - llm-service

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    restart: unless-stopped
    privileged: true
    expose:
      - "8080"
    networks:
      - llm-service
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro

  dcgm-exporter:
    image: nvidia/dcgm-exporter:latest
    container_name: dcgm-exporter
    restart: unless-stopped
    runtime: nvidia
    expose:
      - "9401"
    cap_add:
      - SYS_ADMIN
    networks:
      - llm-service
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  # Uncomment the following section if you want to use Ollama
  # Note: Ollama requires a GPU and the NVIDIA runtime.
  # Make sure to have the NVIDIA Container Toolkit installed.
  # If you want to use Ollama, ensure that the NVIDIA runtime is available and configured
  # properly on your Docker host.
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   restart: unless-stopped
  #   expose:
  #     - "11434"
  #   volumes:
  #     - ./ollama_data:/root/.ollama
  #   networks:
  #     - llm-service
  #   runtime: nvidia
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]

  flowise:
    image: flowiseai/flowise:latest
    container_name: flowise
    restart: unless-stopped
    expose:
      - "3000"
    environment:
      - DATABASE_PATH=/root/.flowise
    volumes:
      - ./flowise_data:/root/.flowise
    networks:
      - llm-service

  neo4j:
    image: neo4j:latest
    container_name: neo4j
    restart: unless-stopped
    environment:
      - NEO4J_AUTH=${NEO4J_USER:-neo4j}/${NEO4J_PASSWORD:-password}
      - dbms.usage_report.enabled=false
    expose:
      - "7474"
      - "7687"
    ports:
    - "7687:7687"
    volumes:
      - ./neo4j_data:/data
    networks:
      - llm-service

  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    restart: unless-stopped
    expose:
      - "8080"
    environment:
      - BASE_URL=http://localhost:8080/
    volumes:
      - ./searxng_data:/etc/searxng
    networks:
      - llm-service

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    environment:
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_DATABASE=${N8N_DB}
      - DB_POSTGRESDB_USER=${POSTGRES_USER}
      - DB_POSTGRESDB_PASSWORD=${POSTGRES_PASSWORD}
      - N8N_PORT=5678
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_BASIC_AUTH_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_BASIC_AUTH_PASSWORD}
    expose:
      - "5678"
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - llm-service

  minio:
    image: minio/minio
    container_name: minio
    restart: unless-stopped
    command: server --address ":9000" --console-address ":9001" /data
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    expose:
      - "9000" 
      - "9001" # MinIO WebInterfase
    ports:
      - "9100:9000"  # MinIO API
    volumes:
      - ./minio_data:/data
    networks:
      - llm-service

  langfuse-worker:
    image: ghcr.io/langfuse/langfuse-worker:latest
    container_name: langfuse-worker
    restart: unless-stopped
    depends_on:
      - postgres
      - minio
      - redis
      - clickhouse
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/langfuse
      SALT: ${LANGFUSE_SALT}
      ENCRYPTION_KEY: ${ENCRYPTION_KEY}
      TELEMETRY_ENABLED: ${TELEMETRY_ENABLED:-true}
      LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES: ${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-true}
      CLICKHOUSE_MIGRATION_URL: clickhouse://clickhouse:9000
      CLICKHOUSE_URL: http://clickhouse:8123
      CLICKHOUSE_USER: clickhouse
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      CLICKHOUSE_CLUSTER_ENABLED: ${CLICKHOUSE_CLUSTER_ENABLED:-false}
      LANGFUSE_S3_EVENT_UPLOAD_BUCKET: langfuse
      LANGFUSE_S3_EVENT_UPLOAD_REGION: auto
      LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID: minio
      LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT: http://minio:9000
      LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE: "true"
      LANGFUSE_S3_EVENT_UPLOAD_PREFIX: events/
      LANGFUSE_S3_MEDIA_UPLOAD_BUCKET: langfuse
      LANGFUSE_S3_MEDIA_UPLOAD_REGION: auto
      LANGFUSE_S3_MEDIA_UPLOAD_ACCESS_KEY_ID: minio
      LANGFUSE_S3_MEDIA_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      LANGFUSE_S3_MEDIA_UPLOAD_ENDPOINT: http://minio:9000
      LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE: "true"
      LANGFUSE_S3_MEDIA_UPLOAD_PREFIX: media/
      LANGFUSE_S3_BATCH_EXPORT_ENABLED: "false"
      LANGFUSE_S3_BATCH_EXPORT_BUCKET: langfuse
      LANGFUSE_S3_BATCH_EXPORT_PREFIX: exports/
      LANGFUSE_S3_BATCH_EXPORT_REGION: auto
      LANGFUSE_S3_BATCH_EXPORT_ENDPOINT: http://minio:9000
      LANGFUSE_S3_BATCH_EXPORT_EXTERNAL_ENDPOINT: http://minio:9000
      LANGFUSE_S3_BATCH_EXPORT_ACCESS_KEY_ID: minio
      LANGFUSE_S3_BATCH_EXPORT_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE: "true"
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_AUTH: LOCALONLYREDIS
      REDIS_TLS_ENABLED: "false"
    networks:
      - llm-service

  langfuse:
    image: ghcr.io/langfuse/langfuse:latest
    container_name: langfuse
    restart: unless-stopped
    depends_on:
      - postgres
      - minio
      - redis
      - clickhouse
    expose:
      - "3000"
    environment:
      DATABASE_URL: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${LANGFUSE_DB}
      SALT: ${LANGFUSE_SALT}
      ENCRYPTION_KEY: ${ENCRYPTION_KEY}
      TELEMETRY_ENABLED: ${TELEMETRY_ENABLED:-true}
      LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES: ${LANGFUSE_ENABLE_EXPERIMENTAL_FEATURES:-true}
      CLICKHOUSE_MIGRATION_URL: clickhouse://clickhouse:9000
      CLICKHOUSE_URL: http://clickhouse:8123
      CLICKHOUSE_USER: clickhouse
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
      CLICKHOUSE_CLUSTER_ENABLED: ${CLICKHOUSE_CLUSTER_ENABLED:-false}
      LANGFUSE_S3_EVENT_UPLOAD_BUCKET: langfuse
      LANGFUSE_S3_EVENT_UPLOAD_REGION: auto
      LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID: minio
      LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      LANGFUSE_S3_EVENT_UPLOAD_ENDPOINT: http://minio:9000
      LANGFUSE_S3_EVENT_UPLOAD_FORCE_PATH_STYLE: "true"
      LANGFUSE_S3_EVENT_UPLOAD_PREFIX: events/
      LANGFUSE_S3_MEDIA_UPLOAD_BUCKET: langfuse
      LANGFUSE_S3_MEDIA_UPLOAD_REGION: auto
      LANGFUSE_S3_MEDIA_UPLOAD_ACCESS_KEY_ID: minio
      LANGFUSE_S3_MEDIA_UPLOAD_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      LANGFUSE_S3_MEDIA_UPLOAD_ENDPOINT: http://minio:9000
      LANGFUSE_S3_MEDIA_UPLOAD_FORCE_PATH_STYLE: "true"
      LANGFUSE_S3_MEDIA_UPLOAD_PREFIX: media/
      LANGFUSE_S3_BATCH_EXPORT_ENABLED: "false"
      LANGFUSE_S3_BATCH_EXPORT_BUCKET: langfuse
      LANGFUSE_S3_BATCH_EXPORT_PREFIX: exports/
      LANGFUSE_S3_BATCH_EXPORT_REGION: auto
      LANGFUSE_S3_BATCH_EXPORT_ENDPOINT: http://minio:9000
      LANGFUSE_S3_BATCH_EXPORT_EXTERNAL_ENDPOINT: http://minio:9000
      LANGFUSE_S3_BATCH_EXPORT_ACCESS_KEY_ID: minio
      LANGFUSE_S3_BATCH_EXPORT_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      LANGFUSE_S3_BATCH_EXPORT_FORCE_PATH_STYLE: "true"
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_AUTH: LOCALONLYREDIS
      REDIS_TLS_ENABLED: "false"
      NEXTAUTH_URL: http://localhost:3003
      NEXTAUTH_SECRET: ${NEXTAUTH_SECRET}
      LANGFUSE_INIT_ORG_ID: ${LANGFUSE_INIT_ORG_ID:-}
      LANGFUSE_INIT_ORG_NAME: ${LANGFUSE_INIT_ORG_NAME:-}
      LANGFUSE_INIT_PROJECT_ID: ${LANGFUSE_INIT_PROJECT_ID:-}
      LANGFUSE_INIT_PROJECT_NAME: ${LANGFUSE_INIT_PROJECT_NAME:-}
      LANGFUSE_INIT_PROJECT_PUBLIC_KEY: ${LANGFUSE_INIT_PROJECT_PUBLIC_KEY:-}
      LANGFUSE_INIT_PROJECT_SECRET_KEY: ${LANGFUSE_INIT_PROJECT_SECRET_KEY:-}
      LANGFUSE_INIT_USER_EMAIL: ${LANGFUSE_INIT_USER_EMAIL:-}
      LANGFUSE_INIT_USER_NAME: ${LANGFUSE_INIT_USER_NAME:-}
      LANGFUSE_INIT_USER_PASSWORD: ${LANGFUSE_INIT_USER_PASSWORD:-}
    networks:
      - llm-service

  clickhouse:
    image: clickhouse/clickhouse-server
    container_name: clickhouse
    restart: unless-stopped
    user: "101:101"
    expose:
      - "8123"   # HTTP interface
      - "9000"   # Native TCP interface
      - "9009"   # Inter-server communication
    environment:
      CLICKHOUSE_DB: default
      CLICKHOUSE_USER: clickhouse
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD}
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - clickhouse_logs:/var/log/clickhouse-server
    healthcheck:
      test: wget --no-verbose --tries=1 --spider http://localhost:8123/ping || exit 1
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 1s
    networks:
      - llm-service
